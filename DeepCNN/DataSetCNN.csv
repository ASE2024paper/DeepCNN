label,code
SE,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 4 4 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
SE,Sequential Conv2D 32 kernel_size 4 4 strides 2 2 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
SE,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
SE,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,Sequential Conv2D 32 kernel_size 4 4 strides 3 3 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
SE,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 4 4 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
SE,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
SE,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
SE,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
SE,Sequential Conv2D 32 kernel_size 4 4 strides 4 4 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
SE,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
SE,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
SE,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
SE,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 4 4 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 4 4 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 4 4 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 4 4 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 2 2 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,"Sequential Conv2D 32 kernel_size 5 5 strides 2 2 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
SE,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
SE,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
SE,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
SE,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
SE,"Sequential Conv2D 32 kernel_size 5 5 strides 3 3 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 3 3 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
SE,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 3 3 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
SE,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,Sequential Conv2D 16 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
SE,Sequential Conv2D 16 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,Sequential Conv2D 256 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 2 2 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
SE,Sequential Conv2D 256 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,Sequential Conv2D 256 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,"Sequential Conv2D 32 kernel_size 3 3 strides 2 2 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 2 2 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 2 2 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
SE,Sequential Conv2D 16 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
SE,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
SE,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
SE,Sequential Conv2D 16 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
SE,"Sequential Conv2D 32 kernel_size 3 3 strides 3 3 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
SE,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 2 2 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 2 2 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 2 2 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,Sequential Conv2D 32 kernel_size 5 5 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
SE,"Sequential Conv2D 32 kernel_size 3 3 strides 3 3 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 3 3 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 3 3 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
SE,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
SE,Sequential Conv2D 16 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
SE,Sequential Conv2D 16 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
SE,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
SE,Sequential Conv2D 256 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 4 4 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
SE,Sequential Conv2D 32 kernel_size 5 5 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
SE,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 3 3 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
SE,"Sequential Conv2D 32 kernel_size 3 3 strides 4 4 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 4 4 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 4 4 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 4 4 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
SE,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
SE,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
SE,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
SE,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 2 2 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
SE,Sequential Conv2D 32 kernel_size 5 5 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
SE,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 4 4 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
SE,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 2 2 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 3 3 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 4 4 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
SE,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 3 3 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
SE,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 4 4 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 3 3 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
SE,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 2 2 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 3 3 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 3 3 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 3 3 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 3 3 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
SE,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,"Sequential Conv2D 32 kernel_size 5 5 strides 2 2 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
SE,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
SE,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
SE,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
SE,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 4 4 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
SE,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,"Sequential Conv2D 32 kernel_size 3 3 strides 4 4 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,Sequential Conv2D 256 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 2 2 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 2 2 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 2 2 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 4 4 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
SE,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
SE,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 2 2 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,"Sequential Conv2D 32 kernel_size 3 3 strides 2 2 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
SE,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 3 3 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 4 4 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 2 2 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 2 2 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 3 3 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
SE,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 3 3 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,Sequential Conv2D 64 kernel_size 3 3 strides 2 2 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
SE,Sequential Conv2D 256 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 4 4 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
SE,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
SE,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,"Sequential Conv2D 32 kernel_size 5 5 strides 3 3 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
SE,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 3 3 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 3 3 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 3 3 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 2 2 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
SE,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,"Sequential Conv2D 64 kernel_size 5 5 strides 4 4 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 4 4 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 4 4 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
SE,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
SE,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 4 4 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 4 4 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
SE,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 3 3 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,"Sequential Conv2D 32 kernel_size 5 5 strides 4 4 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
SE,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 2 2 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
SE,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 3 3 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 3 3 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
SE,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 2 2 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 2 2 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
SE,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 2 2 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
SE,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,"Sequential Conv2D 32 kernel_size 5 5 strides 4 4 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 4 4 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 2 2 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
SE,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 3 3 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
SE,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
SE,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 3 3 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
SE,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 3 3 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
PL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 5 5 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
PL,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 1 1 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
PL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 5 5 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 5 5 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 5 5 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 5 5 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 1 1 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
PL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 5 5 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 3 3 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 5 5 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
PL,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 3 3 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
PL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 5 5 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
PL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 3 3 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 3 3 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
PL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 3 3 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 5 5 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 5 5 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
PL,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 5 5 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 3 3 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 5 5 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
PL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 1 1 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 5 5 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 5 5 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 5 5 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 5 5 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
PL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 3 3 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
PL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 5 5 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 3 3 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 5 5 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 1 1 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 1 1 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 1 1 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 1 1 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 1 1 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 1 1 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
PL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 5 5 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 3 3 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
PL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 1 1 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
PL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 3 3 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
PL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 1 1 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 1 1 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
PL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 3 3 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
PL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 1 1 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
PL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 1 1 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 1 1 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 1 1 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
PL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 5 5 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
PL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
PL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 5 5 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
PL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
PL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
PL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
PL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 3 3 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
PL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
PL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 5 5 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 5 5 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 1 1 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 1 1 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
PL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 1 1 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
PL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 5 5 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 1 1 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
PL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 1 1 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
PL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 1 1 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 1 1 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
PL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 1 1 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
PL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 1 1 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
PL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 3 3 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
PL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 5 5 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
PL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 5 5 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
PL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 1 1 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 1 1 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
PL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 3 3 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
PL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 1 1 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 3 3 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 3 3 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 3 3 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
PL,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 5 5 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
PL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 3 3 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
PL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 5 5 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 3 3 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 3 3 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 3 3 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 3 3 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 3 3 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 3 3 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
PL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 5 5 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
PL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 1 1 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 5 5 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
PL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 5 5 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
PL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 3 3 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
PL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 1 1 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
PL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 5 5 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 1 1 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 1 1 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 1 1 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
PL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 3 3 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
PL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 1 1 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
PL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 3 3 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
PL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 3 3 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 3 3 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
PL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 5 5 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 5 5 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
PL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 5 5 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 5 5 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
PL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 5 5 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 5 5 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 5 5 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
PL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 3 3 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
PL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 3 3 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 3 3 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
PL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 3 3 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
PL,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 1 1 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
PL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
PL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 5 5 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
PL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 5 5 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
PL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 3 3 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
PL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 1 1 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
PL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 3 3 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 3 3 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 3 3 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
PL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 1 1 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
PL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 1 1 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
PL,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 3 3 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
PL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 5 5 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
PL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 1 1 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
PL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 5 5 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
PL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 1 1 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 1 1 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 1 1 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 5 5 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
PL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 3 3 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
PL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 3 3 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 3 3 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 3 3 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
PL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 5 5 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 5 5 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
PL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 3 3 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 3 3 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
PL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 1 1 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 1 1 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
PL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 1 1 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
PL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
PL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 1 1 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 1 1 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 1 1 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
PL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 3 3 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
PL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 1 1 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
PL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 5 5 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 5 5 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
PL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 1 1 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
PL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 5 5 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 5 5 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
PL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 3 3 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 1 1 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
PL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 5 5 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 5 5 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 5 5 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
PL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 1 1 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 5 5 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
PL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 1 1 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
PL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 3 3 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 3 3 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
PL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 1 1 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 1 1 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
PL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 1 1 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
PL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 5 5 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
PL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 5 5 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
PL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 3 3 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
PL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 3 3 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
PL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 3 3 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
PL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
PL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 3 3 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 3 3 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
PL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 3 3 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
PL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 3 3 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 256 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
DU,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 256 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 512 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 128 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
DU,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 128 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
DU,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 64 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
DU,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 1024 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
DU,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 128 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
DU,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 64 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
DU,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 1024 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
DU,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 512 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
DU,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 1024 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 1024 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
DU,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 128 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
DU,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 256 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 512 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
DU,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 512 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
DU,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 64 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 512 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
DU,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 64 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
DU,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 512 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 256 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
DU,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 1024 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 64 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
DU,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 1024 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 128 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 256 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
DU,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 128 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 1024 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
DU,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 256 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
DU,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 64 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
DU,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 1024 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
DU,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 512 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
DU,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 1024 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
DU,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 64 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
DU,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 1024 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
DU,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 128 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 64 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 256 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
DU,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 256 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
DU,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 64 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
DU,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 256 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
DU,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 1024 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
DU,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 128 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
DU,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 512 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 128 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
DU,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 64 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
DU,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 1024 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
DU,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 512 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
DU,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 64 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
DU,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 256 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
DU,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 256 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
DU,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 128 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
DU,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 64 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
DU,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 256 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
DU,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 1024 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
DU,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 512 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
DU,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 512 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
DU,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 256 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
DU,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 512 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 1024 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
DU,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 128 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
DU,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 64 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
DU,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 1024 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
DU,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 64 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
DU,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 512 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
DU,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 256 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
DU,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 256 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 64 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
DU,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 128 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
DU,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 512 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
DU,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 128 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
DU,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 512 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
DU,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 1024 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
DU,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
DU,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 64 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
DU,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 64 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
DU,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 512 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
DU,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 128 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 256 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
DU,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 1024 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 512 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 64 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 64 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 1024 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 512 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 128 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 64 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 128 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 1024 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 512 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 256 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 512 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
DU,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 1024 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 128 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
DU,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 1024 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,model1 Sequential model1 Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KL,Sequential Conv2D 64 kernel_size 7 7 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,"Sequential Conv2D 32 kernel_size 1 1 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 1 1 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 1 1 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 5 5 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 7 7 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,model1 Sequential model1 Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 1 1 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,"Sequential Conv2D 32 kernel_size 7 7 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 7 7 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 7 7 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 4 4 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
KL,Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,Sequential Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,Sequential Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 7 7 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 1 1 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,model1 Sequential model1 Conv2D 16 kernel_size 4 4 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,Sequential Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 4 4 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 1 1 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KL,Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KL,Sequential Conv2D 256 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 5 5 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 5 5 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
KL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,"Sequential Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,Sequential Conv2D 256 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 7 7 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KL,Sequential Conv2D 16 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,Sequential Conv2D 16 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,"Sequential Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KL,"Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,"Sequential Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,Sequential Conv2D 16 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,"Sequential Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,Sequential Conv2D 256 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,Sequential Conv2D 256 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,Sequential Conv2D 256 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,Sequential Conv2D 64 kernel_size 4 4 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"Sequential Conv2D 32 kernel_size 1 1 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 5 5 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,Sequential Conv2D 64 kernel_size 4 4 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 4 4 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 4 4 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,Sequential Conv2D 16 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 1 1 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 4 4 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,model1 Sequential model1 Conv2D 16 kernel_size 1 1 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KL,"Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 4 4 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 4 4 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,Sequential Conv2D 256 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 7 7 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,model1 Sequential model1 Conv2D 16 kernel_size 1 1 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 1 1 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,Sequential Conv2D 64 kernel_size 1 1 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 1 1 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 1 1 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,Sequential Conv2D 64 kernel_size 7 7 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,Sequential Conv2D 16 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KL,Sequential Conv2D 16 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KL,"Sequential Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,Sequential Conv2D 64 kernel_size 1 1 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,model1 Sequential model1 Conv2D 16 kernel_size 7 7 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KL,Sequential Conv2D 64 kernel_size 1 1 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,Sequential Conv2D 256 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"Sequential Conv2D 32 kernel_size 7 7 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 1 1 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 4 4 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 7 7 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KL,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"Sequential Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,Sequential Conv2D 16 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KL,"Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,"Sequential Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,Sequential Conv2D 256 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 5 5 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,Sequential Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
KL,"Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 7 7 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
KL,Sequential Conv2D 64 kernel_size 5 5 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,model1 Sequential model1 Conv2D 16 kernel_size 7 7 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 7 7 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KL,Sequential Conv2D 16 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KL,"Sequential Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,"Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 4 4 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KL,"Sequential Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,Sequential Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
KL,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KL,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KL,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KL,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 1 1 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KL,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KL,Sequential Conv2D 64 kernel_size 4 4 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KL,"Sequential Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,Sequential Conv2D 64 kernel_size 7 7 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 7 7 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 7 7 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KL,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KL,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KL,Sequential Conv2D 32 kernel_size 7 7 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,model1 Sequential model1 Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KL,model1 Sequential model1 Conv2D 16 kernel_size 5 5 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 5 5 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KL,model1 Sequential model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KL,model1 Sequential model1 Conv2D 16 kernel_size 4 4 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KL,Sequential Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,Sequential Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 5 5 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KL,model1 Sequential model1 Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,model1 Sequential model1 Conv2D 16 kernel_size 5 5 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KL,model1 Sequential model1 Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KL,model1 Sequential model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KL,Sequential Conv2D 32 kernel_size 1 1 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,Sequential Conv2D 64 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 7 7 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KL,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KL,Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
KL,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KL,model1 Sequential model1 Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 1 1 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer zeros input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_normal MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer lecun_normal activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer zeros input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer lecun_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_normal activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_normal input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer lecun_normal input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer lecun_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_normal activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer lecun_normal activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer he_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_normal input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer zeros MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KI,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer zeros MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer lecun_normal activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer lecun_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer zeros activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer zeros activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer zeros input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_normal model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_normal activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer he_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer he_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer zeros activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer he_normal activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer he_normal activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer he_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer zeros activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer lecun_normal activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_normal activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_normal input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer zeros activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer lecun_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer zeros activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_normal activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KI,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KI,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KI,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer lecun_normal activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer he_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer he_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer lecun_normal activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_normal activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer lecun_normal MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KI,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer lecun_normal input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
KI,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KI,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer he_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
KI,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KI,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer lecun_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer lecun_normal activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer he_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer lecun_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer he_normal Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer lecun_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer lecun_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer zeros input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer lecun_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer he_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer zeros activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer lecun_normal model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer lecun_normal input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer he_normal activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KI,Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer he_normal input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
KI,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_normal MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer lecun_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_normal input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer he_normal activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_normal activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer zeros Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KI,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer zeros model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_normal activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_normal MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer lecun_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer lecun_normal MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_normal model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer lecun_normal activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer zeros activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer he_normal activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer he_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer lecun_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
KI,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer lecun_normal input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_normal input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer lecun_normal Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_normal Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KI,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer he_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer zeros MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer lecun_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer he_normal activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer lecun_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer lecun_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
KI,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer zeros input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer he_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
KI,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer lecun_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer lecun_normal input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer lecun_normal MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KI,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_normal input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_normal input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_normal input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer he_normal input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer lecun_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer lecun_normal input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KI,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
KI,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KI,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer he_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer lecun_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_normal MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer he_normal activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
KI,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer he_normal activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
KI,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_normal MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
KI,Sequential Conv2D 32 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer he_normal MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
KI,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer he_normal input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
KI,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer zeros input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
KI,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer he_normal LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 8 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
FR,"keras models Sequential keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,model1 Sequential model1 Conv2D 256 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,"Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 16 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 16 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,Sequential Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,Sequential Conv2D 128 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
FR,"keras models Sequential keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 256 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 32 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
FR,"Sequential Conv2D 16 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 256 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,Sequential Conv2D 128 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 512 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 512 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
FR,"keras models Sequential keras layers Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 128 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 512 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
FR,"keras models Sequential keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 64 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,Sequential Conv2D 8 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
FR,"keras models Sequential keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 8 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 16 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 128 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 128 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
FR,Sequential Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 8 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,"Sequential Conv2D 512 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 16 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 32 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 16 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 16 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"cnn Sequential cnn Conv2D 512 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 256 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 16 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 16 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 16 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 16 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 128 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"Sequential Conv2D 16 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,Sequential Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,"Sequential Conv2D 16 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 16 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 16 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 8 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 128 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 256 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"cnn Sequential cnn Conv2D 32 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 32 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 32 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 32 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 512 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 256 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,Sequential Conv2D 512 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,Sequential Conv2D 8 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,"Sequential Conv2D 128 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 512 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"cnn Sequential cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 16 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 16 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 256 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,Sequential Conv2D 8 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,model1 Sequential model1 Conv2D 16 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 256 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 16 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,model1 Sequential model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 256 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"cnn Sequential cnn Conv2D 32 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 256 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"Sequential Conv2D 128 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 8 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 256 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,model1 Sequential model1 Conv2D 8 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,model1 Sequential model1 Conv2D 8 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 8 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 256 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,Sequential Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,"Sequential Conv2D 8 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,model1 Sequential model1 Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,model1 Sequential model1 Conv2D 8 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 8 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"Sequential Conv2D 256 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 32 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 512 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 512 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,model1 Sequential model1 Conv2D 256 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 8 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 256 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,Sequential Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,cnn tf keras models Sequential cnn tf keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape =[ 150 150 3 ])) cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu cnn tf keras layers MaxPool2D pool_size 2 2 strides 2 2 padding same cnn tf keras layers Flatten cnn tf keras layers Dense 128 activation relu cnn tf keras layers Dense 8 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics [' accuracy cnn fit x train_gen validation_data val_gen epochs 15 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 8 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,model1 Sequential model1 Conv2D 128 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 512 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 8 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 512 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 8 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 8 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 8 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 8 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,model1 Sequential model1 Conv2D 512 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,"Sequential Conv2D 8 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 8 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 8 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,Sequential Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 200 200 3 activation relu Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 30 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 3 3 padding same Dropout 0 25 Flatten Dense 32 activation relu Dense 32 activation relu Dense units 1 activation sigmoid compile optimizer adam loss binary_crossentropy metrics accuracy history fit train epochs 30 validation_data test callbacks =[ es ]) 
FR,"Sequential Conv2D 8 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu input_shape 28 28 1 ))) BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation elu BatchNormalization Dropout 0 3 AvgPool2D pool_size 2 2 padding same BatchNormalization Dropout 0 3 Flatten Dense 300 activation "" elu BatchNormalization Dropout 0 3 Dense 200 activation "" elu BatchNormalization Dropout 0 3 Dense 100 activation "" elu BatchNormalization Dropout 0 3 Dense 10 activation "" softmax compile loss sparse_categorical_crossentropy optimizer rmsprop metrics acc early_stopping EarlyStopping min_delta 0 0002 mode min patience 20 restore_best_weights True print ("" Num GPUs Available : len tf config list_physical_devices (' GPU '))) history fit X_tr y_tr validation_data X_val y_val verbose 1 epochs 50 batch_size 16 callbacks =[ early_stopping ])  "
FR,Sequential Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,"Sequential tf keras layers experimental preprocessing Rescaling 1 ./ 255 Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 224 224 3 ))) Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform Activation (' relu MaxPooling2D pool_size 2 2 strides 2 2 padding same Flatten Dense 256 Activation (' relu Dropout 0 2 Dense 9 Activation (' softmax compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) hst fit X_train validation_data X_val epochs EPOCHS "
FR,model1 Sequential model1 Conv2D 8 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,model1 Sequential model1 Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform input_shape 28 28 1 ))) model1 MaxPooling2D pool_size 2 2 padding same model1 Conv2D 128 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer he_uniform model1 MaxPooling2D pool_size 2 2 padding same model1 Flatten model1 Dense 100 activation relu kernel_initializer he_uniform model1 Dense 64 activation relu kernel_initializer he_uniform model1 Dense 10 activation softmax model1 compile optimizer Adam loss categorical_crossentropy metrics accuracy history1 model1 fit x_train y_train batch_size 32 epochs 10 validation_data x_val y_val 
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 32 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 8 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"cnn Sequential cnn Conv2D 256 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 150 150 3 ))) cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 64 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Conv2D 128 activation relu kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform cnn MaxPool2D pool_size 2 2 strides 2 2 padding same cnn Flatten cnn Dropout 0 2 cnn Dense 512 activation relu cnn Dense 3 activation softmax cnn compile optimizer adam loss categorical_crossentropy metrics =["" accuracy ""]) history cnn fit train_generator validation_data test_generator epochs 10 steps_per_epoch 20 validation_steps 3 callbacks =[ callback ]) "
FR,"keras models Sequential keras layers Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,"Sequential Conv2D 16 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 32 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
FR,model1 Sequential model1 Conv2D 64 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 512 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 3 activation relu MaxPooling2D pool_size 2 2 padding same BatchNormalization Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Dropout 0 2 Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu Flatten Dense 24 activation relu Dropout 0 2 Dense 12 activation relu Dropout 0 2 Dense len Label activation softmax compile optimizer adam loss keras losses SparseCategoricalCrossentropy metrics accuracy history fit X_tr y_smote epochs 50 batch_size 32 validation_split 0 2 shuffle True 
FR,Sequential Conv2D 16 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
FR,"Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 8 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 input_shape 128 128 1 padding same kernel_initializer glorot_uniform activation relu MaxPool2D pool_size 8 8 padding same Conv2D 16 kernel_size 3 3 strides 1 1 activation relu padding same kernel_initializer glorot_uniform Flatten Dense 6 activation softmax compile (' SGD loss categorical_crossentropy metrics [' accuracy fit x X_train y Y_train batch_size 128 epochs 10 validation_split 0 2 
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,Sequential Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,"Sequential Conv2D 8 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"Sequential Conv2D 64 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 64 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
FR,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 256 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 512 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,"Sequential Conv2D 8 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 8 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 8 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,model1 Sequential model1 Conv2D 128 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"keras models Sequential keras layers Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,"keras models Sequential keras layers Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,"Sequential Conv2D 8 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"Sequential Conv2D 512 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,Sequential Conv2D 256 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
FR,model1 Sequential model1 Conv2D 16 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 16 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 8 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,"Sequential Conv2D 256 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,"Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 16 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,Sequential Conv2D 8 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 8 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"keras models Sequential keras layers Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 256 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,"Sequential Conv2D 256 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,model1 Sequential model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 512 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,Sequential Conv2D 16 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
FR,Sequential Conv2D 128 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,Sequential Conv2D 8 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
FR,"Sequential Conv2D 512 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,"Sequential Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 128 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 16 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,"Sequential Conv2D 32 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu input_shape 128 128 3 ))) MaxPooling2D pool_size 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Conv2D 64 kernel_size 3 3 strides 1 1 padding Same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 strides 2 2 padding Same Dropout 0 25 Flatten Dense 256 activation "" relu Dense 3 activation "" softmax compile loss categorical_crossentropy optimizer adam metrics =["" accuracy ""]) history fit train_im validation_data val_im epochs 25 steps_per_epoch 100 callbacks =[ callbacks ]) "
FR,Sequential Conv2D 512 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 64 64 1 activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense num_classes activation softmax compile optimizer Adam learning_rate 0 01 loss categorical_crossentropy metrics [' accuracy model1 fit x_train y_train batch_size 128 epochs 20   
FR,Sequential Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform input_shape 28 28 1 MaxPooling2D pool_size 2 2 padding same Conv2D 512 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 6 activation relu Dropout 0 20 Dense num_classes activation softmax compile loss keras losses categorical_crossentropy optimizer keras optimizers Adam metrics accuracy history fit x_train y_train validation_data x_test y_test epochs epochs batch_size batch_size 
FR,Sequential Conv2D 512 kernel_size 4 4 strides 1 1 padding same input_shape 28 28 1 activation relu kernel_initializer glorot_uniform MaxPooling2D pool_size 2 2 padding same Flatten Dense 128 activation relu Dense 10 activation softmax compile loss categorical_crossentropy optimizer rmsprop metrics accuracy fit x_train1 y_train1 validation_data x_val y_val epochs 1 
FR,model1 Sequential model1 Conv2D 512 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Conv2D 32 kernel_size 4 4 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 32 32 3 activation relu model1 MaxPool2D pool_size 2 2 padding same model1 Flatten model1 Dense 256 activation relu model1 Dense 10 activation softmax model1 compile loss categorical_crossentropy optimizer adam metrics accuracy history1 model1 fit x_train y_train_cat epochs 20 validation_data x_test y_test_cat 
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,"Sequential Conv2D 32 kernel_size 5 5 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 32 32 3 ))) MaxPooling2D pool_size 2 2 padding same Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu MaxPooling2D pool_size 2 2 padding same Flatten Dense 100 activation relu Dropout 0 25 Dense 2 activation softmax compile loss categorical_crossentropy optimizer Adam metrics accuracy history fit X_train y_train epochs 20 scores evaluate X_test y_test verbose 0 print ("" Test Accuracy :""+""% s : %. 2f %%"" % metrics_names [ 1 ], scores [ 1 ]* 100 "
FR,Sequential Conv2D 16 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform input_shape 28 28 1 ))) LeakyReLU MaxPooling2D pool_size 2 2 padding same Conv2D 512 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform LeakyReLU MaxPooling2D pool_size 2 2 padding same Dropout 0 5 Flatten Dense 512 Dropout 0 5 LeakyReLU Dense 256 LeakyReLU Dropout 0 5 Dense 3 activation softmax compile optimizer adam loss categorical_crossentropy metrics accuracy history fit train_images validation_data val_images epochs 100 callbacks =[ tf keras callbacks ModelCheckpoint ('./ h5 save_best_only True save_weights_only True )]) 
FR,"keras models Sequential keras layers Conv2D 64 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu input_shape 120 120 3 ))) keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 128 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Conv2D 32 kernel_size 3 3 strides 1 1 padding same kernel_initializer glorot_uniform activation relu keras layers MaxPooling2D pool_size 2 2 padding same keras layers Dropout (. 25 keras layers Flatten keras layers Dense 1024 activation relu keras layers Dropout (. 25 keras layers Dense 4 activation softmax compile optimizer adam loss sparse_categorical_crossentropy metrics accuracy result fit train_image train_label epochs epochs batch_size 32 validation_data val_image val_label last_epoch_loss result history [' loss '][- 1 ] last_epoch_acc result history [' accuracy '][- 1 ] print ("" Final Result : loss ={ 0 } : accuracy ={ 1 } : fileName : { 2 }"". format last_epoch_loss last_epoch_acc os path basename __file__ ))) "
